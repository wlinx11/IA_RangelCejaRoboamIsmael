{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "img = cv2.imread('Imagenes/robo/roboHabitacion8.jpg')\n",
    "print(img.shape[0], img.shape[1], img.shape[2], len(img.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:12:59.231970Z",
     "start_time": "2018-11-08T00:12:51.800950Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:13:12.550878Z",
     "start_time": "2018-11-08T00:12:59.234748Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, Conv2D\n",
    ")\n",
    "from keras.layers import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar set de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:45.248080Z",
     "start_time": "2018-11-08T00:13:12.553292Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(),'Imagenes')\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            if(len(image.shape)==3):\n",
    "                \n",
    "                images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:45.269861Z",
     "start_time": "2018-11-08T00:16:45.251786Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:45.285925Z",
     "start_time": "2018-11-08T00:16:45.273489Z"
    }
   },
   "outputs": [],
   "source": [
    "risk=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    risk.append(name[len(name)-1])\n",
    "    indice=indice+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:45.498672Z",
     "start_time": "2018-11-08T00:16:45.290061Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos Sets de Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:45.669596Z",
     "start_time": "2018-11-08T00:16:45.502716Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:49.319746Z",
     "start_time": "2018-11-08T00:16:45.673944Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:50.798162Z",
     "start_time": "2018-11-08T00:16:49.322999Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X/255.\n",
    "test_X = test_X/255.\n",
    "plt.imshow(test_X[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacemos el One-hot Encoding para la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:50.815482Z",
     "start_time": "2018-11-08T00:16:50.800831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el Set de Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.218520Z",
     "start_time": "2018-11-08T00:16:50.818992Z"
    }
   },
   "outputs": [],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.228116Z",
     "start_time": "2018-11-08T00:16:51.222460Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.244776Z",
     "start_time": "2018-11-08T00:16:51.238704Z"
    }
   },
   "outputs": [],
   "source": [
    "#declaramos variables con los parámetros de configuración de la red\n",
    "INIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
    "epochs = 30 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
    "batch_size = 64 # cantidad de imágenes que se toman a la vez en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.384131Z",
     "start_time": "2018-11-08T00:16:51.252188Z"
    }
   },
   "outputs": [],
   "source": [
    "risk_model = Sequential()\n",
    "risk_model.add(Input(shape=(28, 28, 3)))  # Medida de las imagenes procesar 28x28\n",
    "risk_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "risk_model.add(LeakyReLU(negative_slope=0.1))\n",
    "risk_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "risk_model.add(Dropout(0.5))\n",
    "\n",
    "risk_model.add(Flatten())\n",
    "risk_model.add(Dense(32, activation='linear'))\n",
    "risk_model.add(LeakyReLU(negative_slope=0.1))\n",
    "risk_model.add(Dropout(0.5))\n",
    "risk_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.401674Z",
     "start_time": "2018-11-08T00:16:51.386676Z"
    }
   },
   "outputs": [],
   "source": [
    "risk_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:16:51.472349Z",
     "start_time": "2018-11-08T00:16:51.406817Z"
    }
   },
   "outputs": [],
   "source": [
    "INIT_LR = 0.01  # Tasa de aprendizaje inicial\n",
    "decay_steps = 100  # Número de pasos de decaimiento (puedes ajustarlo según sea necesario)\n",
    "decay_rate = 0.96  # Factor de decaimiento (puedes ajustarlo según sea necesario)\n",
    "\n",
    "# Definir el programador de tasa de aprendizaje\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Compilar el modelo con el optimizador actualizado\n",
    "risk_model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamos el modelo: Aprende a clasificar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:49.562522Z",
     "start_time": "2018-11-08T00:16:51.474807Z"
    }
   },
   "outputs": [],
   "source": [
    "risk_train = risk_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:49.676566Z",
     "start_time": "2018-11-08T00:20:49.566203Z"
    }
   },
   "outputs": [],
   "source": [
    "# guardar el modelo en el nuevo formato\n",
    "risk_model.save(\"C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//risk_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:54.462929Z",
     "start_time": "2018-11-08T00:20:49.678643Z"
    }
   },
   "outputs": [],
   "source": [
    "test_eval = risk_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:54.474683Z",
     "start_time": "2018-11-08T00:20:54.465378Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risk_train.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:55.014647Z",
     "start_time": "2018-11-08T00:20:54.479693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = risk_train.history['accuracy']\n",
    "val_accuracy = risk_train.history['val_accuracy']\n",
    "loss = risk_train.history['loss']\n",
    "val_loss = risk_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:58.050602Z",
     "start_time": "2018-11-08T00:20:55.021862Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_classes2 = risk_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:58.262575Z",
     "start_time": "2018-11-08T00:20:58.052878Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_classes=[]\n",
    "for predicted_risk in predicted_classes2:\n",
    "    predicted_classes.append(predicted_risk.tolist().index(max(predicted_risk)))\n",
    "predicted_classes=np.array(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:58.272559Z",
     "start_time": "2018-11-08T00:20:58.264703Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_classes.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendamos de los errores: Qué mejorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:20:59.822110Z",
     "start_time": "2018-11-08T00:20:58.275464Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = np.where(predicted_classes == test_Y)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "\n",
    "# Crear una figura\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for i, correct in enumerate(correct[0:9]):\n",
    "    ax = axes[i // 3, i % 3]  # Seleccionar el eje correspondiente\n",
    "    ax.imshow(test_X[correct].reshape(28, 28, 3), cmap='gray', interpolation='none')\n",
    "    ax.set_title(\"{}, {}\".format(risk[predicted_classes[correct]], risk[test_Y[correct]]))\n",
    "    ax.axis('off')  # Opcional: oculta los ejes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:21:00.942267Z",
     "start_time": "2018-11-08T00:20:59.829572Z"
    }
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes != test_Y)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "\n",
    "# Crear una figura\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    ax = axes[i // 3, i % 3]  # Seleccionar el eje correspondiente\n",
    "    ax.imshow(test_X[incorrect].reshape(28, 28, 3), cmap='gray', interpolation='none')\n",
    "    ax.set_title(\"{}, {}\".format(risk[predicted_classes[incorrect]], risk[test_Y[incorrect]]))\n",
    "    ax.axis('off')  # Opcional: oculta los ejes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:21:00.968727Z",
     "start_time": "2018-11-08T00:21:00.947262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "images=[]\n",
    "# AQUI ESPECIFICAMOS UNAS IMAGENES\n",
    "filenames = ['C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//incendio5.jpg']\n",
    "\n",
    "for filepath in filenames:\n",
    "    image = plt.imread(filepath,0)\n",
    "    image_resized = resize(image, (28, 28),anti_aliasing=True,clip=False,preserve_range=True)\n",
    "    images.append(image_resized)\n",
    "\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "test_X = X.astype('float32')\n",
    "test_X = test_X / 255.\n",
    "\n",
    "predicted_classes = risk_model.predict(test_X)\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    print(filenames[i], risk[img_tagged.tolist().index(max(img_tagged))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Definimos una lista para las imágenes y los nombres de archivo\n",
    "images = []\n",
    "filenames = ['C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//inundacionpruebafinal1.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//inundacionpruebafinal2.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//robo3.jpeg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//robof.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//asaltofinal.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//asaltofinal2.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//tornadofinal.jpg',\n",
    "             'C://Users//ASUS//Desktop//universidad//IA//clasificacion de imagenes con python//imagenes//pruebas//tornadofinal2.jpg'\n",
    "            ]\n",
    "\n",
    "# Iteramos sobre los nombres de archivo para cargar y redimensionar las imágenes\n",
    "for filepath in filenames:\n",
    "    image = plt.imread(filepath)  # No especificar 0 para leer en color\n",
    "    image_resized = resize(image, (28, 28), anti_aliasing=True, clip=False, preserve_range=True)\n",
    "    images.append(image_resized)\n",
    "\n",
    "# Convertimos la lista de imágenes a un array numpy\n",
    "X = np.array(images, dtype=np.uint8)\n",
    "test_X = test_X / 255.0\n",
    "\n",
    "# Realizamos la predicción usando el modelo\n",
    "predicted_classes = risk_model.predict(X)\n",
    "\n",
    "# Definimos una lista con las posibles clases (esto depende de tu modelo)\n",
    "risk = ['asalto', 'incendio', 'inundacion', 'robo', 'tornado']  # Ejemplo de clases\n",
    "\n",
    "# Iteramos sobre las predicciones y mostramos la imagen con la predicción correspondiente\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    # Mostramos la imagen original\n",
    "    original_image = plt.imread(filenames[i])  # Cargamos la imagen original para mostrarla\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(f\"Predicción: {risk[np.argmax(img_tagged)]}\")\n",
    "    plt.axis('off')  # Opcional: para ocultar los ejes\n",
    "    plt.show()\n",
    "    \n",
    "    # Imprimimos el nombre del archivo y la predicción\n",
    "    print(filenames[i], risk[np.argmax(img_tagged)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
